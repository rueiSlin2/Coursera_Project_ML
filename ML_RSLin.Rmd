---
title: "Coursera Project - Practical Machine Learning"
author: "Ruei Shiuan Lin"
date: "2/1/2019"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary
The downloaded datasets contain many missing values and case-specific information columns. Thus, it is necessary to do data preprocessing before using it. In this project, three prediction engines, i.e. random forest, classification tree, and boosted, are trained and validated. The random forest predictor has the best accuracy and is used for the prediction quiz.

```{r}
# Load "caret" package and two downloaded data files
library(caret)
setwd("~/Downloads")
trainData <- read.csv("pml-training (1).csv")
testData <- read.csv("pml-testing (1).csv")
```

## A glance at the datasets
The first seven columns contain personal information, case number, date/time, ... Among them, I find for each person, there is a association between "classe" and "cvtd_timestamp", i.e. classe A - E are roughly found orderly in time (please see the next section). In addition, missing values (NA, "", and "#DIV/0!") are found in most rows. It would be better for training the model using the column variables without any missing values (please see "Preprocessing the training data").

```{r}
# A quick look at the datasets
str(trainData)
str(testData)
unique(trainData$user_name)
unique(testData$user_name)
```

## The "cvtd_timestamp" data transformation
I find "classe vs cvtd_timestamp" association for each person. In this regard, a new column (time_numb) is generated for recording the timestamps in a normalized manner.
```{r}
# Generating a "time_numb"" column from "cvtd_timestamp"
carlData <- trainData[trainData$user_name == "carlitos",]
carlData$time_numb[carlData$cvtd_timestamp == "05/12/2011 11:23"] <- 1
carlData$time_numb[carlData$cvtd_timestamp == "05/12/2011 11:24"] <- 2
carlData$time_numb[carlData$cvtd_timestamp == "05/12/2011 11:25"] <- 3

adelData <- trainData[trainData$user_name == "adelmo",]
adelData$time_numb[adelData$cvtd_timestamp == "02/12/2011 13:32"] <- 1
adelData$time_numb[adelData$cvtd_timestamp == "02/12/2011 13:33"] <- 2
adelData$time_numb[adelData$cvtd_timestamp == "02/12/2011 13:34"] <- 3
adelData$time_numb[adelData$cvtd_timestamp == "02/12/2011 13:35"] <- 4

charlData <- trainData[trainData$user_name == "charles",]
charlData$time_numb[charlData$cvtd_timestamp == "02/12/2011 14:56"] <- 1
charlData$time_numb[charlData$cvtd_timestamp == "02/12/2011 14:57"] <- 2
charlData$time_numb[charlData$cvtd_timestamp == "02/12/2011 14:58"] <- 3
charlData$time_numb[charlData$cvtd_timestamp == "02/12/2011 14:59"] <- 4

euriData <- trainData[trainData$user_name == "eurico",]
euriData$time_numb[euriData$cvtd_timestamp == "28/11/2011 14:13"] <- 1
euriData$time_numb[euriData$cvtd_timestamp == "28/11/2011 14:14"] <- 2
euriData$time_numb[euriData$cvtd_timestamp == "28/11/2011 14:15"] <- 3

jerData <- trainData[trainData$user_name == "jeremy",]
jerData$time_numb[jerData$cvtd_timestamp == "30/11/2011 17:10"] <- 1
jerData$time_numb[jerData$cvtd_timestamp == "30/11/2011 17:11"] <- 2
jerData$time_numb[jerData$cvtd_timestamp == "30/11/2011 17:12"] <- 3

pedData <- trainData[trainData$user_name == "pedro",]
pedData$time_numb[pedData$cvtd_timestamp == "05/12/2011 14:22"] <- 1
pedData$time_numb[pedData$cvtd_timestamp == "05/12/2011 14:23"] <- 2
pedData$time_numb[pedData$cvtd_timestamp == "05/12/2011 14:24"] <- 3
# Combined all to form a new training dataset
newData <- rbind(adelData, carlData, charlData, euriData, jerData, pedData)
plot(newData$time_numb, newData$classe)
```
From the "time_numb vs classe" plot, the association is revealed.

## The "training" dataset partition for model validation
I divide the new training dataset into training portion (75%) and validation portion (25%).
```{r}
# Data partition for training and validation
inTrain <- createDataPartition(newData$classe, p = 3/4)[[1]]
newTraining <- newData[inTrain,]
newTesting <- newData[-inTrain,]
```

## Preprocessing the training data
Three preprocessing are taken for the training and validation datasets: removing the first seven columns, replacing missing values with NA, and removing the columns containing NA.
```{r}
# Remove the first seven columns
newTrainClean <- newTraining[, -c(1:7)]
newTestClean <- newTesting[, -c(1:7)]
# Assign "NA" to missing values
newTrainClean[newTrainClean == ""] <- NA
newTrainClean[newTrainClean == "#DIV/0!"] <- NA
newTrainClean[newTrainClean == "<NA>"] <- NA
newTestClean[newTestClean == ""] <- NA
newTestClean[newTestClean == "#DIV/0!"] <- NA
newTestClean[newTestClean == "<NA>"] <- NA
# Remove columns containing "NA"
col.has.na <- apply(newTrainClean, 2, function(x){any(is.na(x))})
newTrainCleanXna <- newTrainClean[,!col.has.na]
col.has.na2 <- apply(newTestClean, 2, function(x){any(is.na(x))})
newTestCleanXna <- newTestClean[,!col.has.na2]
```

## The random forest prediction and its validation
At first, I train a random forest predictor and perform a validation to find its accuracy.
```{r}
# Training a random forest predictor
set.seed(5678)
modelFitRF <- train(classe~., data = newTrainCleanXna, method = "rf")
modelFitRF
# Validating the random forest model
testpredRF <- predict(modelFitRF, newdata = newTestCleanXna)
confMatRF <- confusionMatrix(testpredRF, newTestCleanXna$classe)
confMatRF
```
The accuracy is pretty good. After checking the other two methods, I decided to use this random forest predictor for the project prediction quiz.

## The classification tree prediction and its validation
Next, a classification tree predictor is constructed and validated.
```{r}
# Training a classification tree predictor
trControl <- trainControl(method = "cv", number = 5)
modelFitCT <- train(classe~., data = newTrainCleanXna, method = "rpart", trControl=trControl)
modelFitCT
# Validating the classification tree model
testpredCT <- predict(modelFitCT, newdata = newTestCleanXna)
confMatCT <- confusionMatrix(testpredCT, newTestCleanXna$classe)
confMatCT
```
The accuracy is much less than the random forest model.

## The boosted prediction and its validation
Finally, a boosted predictor is constructed and validated.
```{r}
# Training a boosted predictor
modelFitGM <- train(classe~., data = newTrainCleanXna, method = "gbm", verbose = FALSE)
```
Now let's see the model and its validation.
```{r}
modelFitGM
# Validating the boosted model
testpredGM <- predict(modelFitGM, newdata = newTestCleanXna)
confMatGM <- confusionMatrix(testpredGM, newTestCleanXna$classe)
confMatGM
```
The accuracy is pretty good but is not better than the random forest model.

## preprocessing the testing data
Now the random forest predictor will be used for the prediction quiz.
```{r}
# Preprocessing and transforming the test data for the prediciton quiz
carlTestData <- testData[testData$user_name == "carlitos",]
carlTestData$time_numb[carlTestData$cvtd_timestamp == "05/12/2011 11:24"] <- 2

adelTestData <- testData[testData$user_name == "adelmo",]
adelTestData$time_numb[adelTestData$cvtd_timestamp == "02/12/2011 13:33"] <- 2

charlTestData <- testData[testData$user_name == "charles",]
charlTestData$time_numb[charlTestData$cvtd_timestamp == "02/12/2011 14:57"] <- 2

euriTestData <- testData[testData$user_name == "eurico",]
euriTestData$time_numb[euriTestData$cvtd_timestamp == "28/11/2011 14:13"] <- 1
euriTestData$time_numb[euriTestData$cvtd_timestamp == "28/11/2011 14:14"] <- 2
euriTestData$time_numb[euriTestData$cvtd_timestamp == "28/11/2011 14:15"] <- 3

jerTestData <- testData[testData$user_name == "jeremy",]
jerTestData$time_numb[jerTestData$cvtd_timestamp == "30/11/2011 17:10"] <- 1
jerTestData$time_numb[jerTestData$cvtd_timestamp == "30/11/2011 17:11"] <- 2
jerTestData$time_numb[jerTestData$cvtd_timestamp == "30/11/2011 17:12"] <- 3

pedTestData <- testData[testData$user_name == "pedro",]
pedTestData$time_numb[pedTestData$cvtd_timestamp == "05/12/2011 14:22"] <- 1
pedTestData$time_numb[pedTestData$cvtd_timestamp == "05/12/2011 14:23"] <- 2

toPredData <- rbind(adelTestData, carlTestData, charlTestData, euriTestData, jerTestData, pedTestData)
toPredDataClean <- toPredData[, -c(1:7)]
toPredDataClean[toPredDataClean == ""] <- NA
toPredDataClean[toPredDataClean == "#DIV/0!"] <- NA
toPredDataClean[toPredDataClean == "<NA>"] <- NA
col.has.na <- apply(toPredDataClean, 2, function(x){any(is.na(x))})
toPredDataCleanXna <- toPredDataClean[,!col.has.na]
```

## The testing data prediction by the random forest model
The final answer is as followed.
```{r}
# Answering the project prediction quiz
predResult <- predict(modelFitRF, newdata = toPredDataCleanXna)
predResult
```

## Reference
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
